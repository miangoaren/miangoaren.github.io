---
title: "Post 8: AI models are getting larger ðŸ’¸"
collection: ai
permalink: /ai/00008_power
date: 2023-01-19
---

&nbsp;


Artificial intelligence wouldn't exist without Graphics Processing Units (GPUs). Although originally designed for video games and multimedia, they are now used for protein modeling and languages. Before GPUs, computing with processors established Moore's Law, which suggests that computing capacity doubles every 2 years. However, in 2012, the AI AlexNet caused a surge in the scientific community's use of GPUs, and now computing capacity doubles every 6 months, leading to the suggestion of a "new law" known as "Huang's Law." While neither are truly laws as they are market phenomena, it's interesting to see how our data processing capacity is growing.

![img](/images/ai/00009_power.jpg)

Here two papers to undestand this trends:
1. [Compute Trends Across Three Eras of Machine Learning](https://arxiv.org/abs/2202.05924)
2. [Dendrocentric learning for synthetic intelligence](https://www.nature.com/articles/s41586-022-05340-6)

and two videos:
1. [To learn about GPUs](https://youtu.be/C_wSHKG8_fg)
2. [Moore/Huang laws](https://youtu.be/Jlbxj182bhg)

