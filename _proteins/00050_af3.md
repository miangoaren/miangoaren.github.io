---
title: "Post 50: AlphaFold3, I'm happy ğŸ¥³ and angry ğŸ˜¡"
collection: proteins
permalink: /proteins/00050_af3
date: 2024-05-10
---

&nbsp;

Today, a [note](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model) and the scientific article for [AlphaFold3](https://www.nature.com/articles/s41586-024-07487-w) were published, but they haven't released the code and only provide a web server with 10 jobs per day. So hereâ€™s my biggest contribution to science so far, a brief series of memes inspired by AlphaFold3:

![img](https://miangoar.github.io/images/proteins/00050_af3_1.png)

We love David Baker's lab ğŸ©·  
![img](https://miangoar.github.io/images/proteins/00050_af3_2.png)

Who would have thought that DeepMind would apply some ["prompt filters"](https://golgi.sandbox.google.com/about) to the input sequences in such a way that analyzing viral sequences is not allowed?  

![img](https://miangoar.github.io/images/proteins/00050_af3_3.png)

ğŸ‘€ğŸ”¥  

![img](https://miangoar.github.io/images/proteins/00050_af3_4.png)

They're fast! Now we need $1 million for training:  
["It could cost upwards of US$1 million in cloud-computing resources to train AlphaFold3"](https://www.nature.com/articles/d41586-024-01555-x)

* [lucidrains GitHub repo](https://github.com/lucidrains/alphafold3-pytorch)

* [kyegomez GitHub repo](https://github.com/kyegomez/AlphaFold3)

![img](https://miangoar.github.io/images/proteins/00050_af3_5.png)

Everything is temporary :(  

![img](https://miangoar.github.io/images/proteins/00050_af3_6.png)

I'm just a marginally stable guy ğŸ”¥  

![img](https://miangoar.github.io/images/proteins/00050_af3_7.png)

It's incredible how almost all the biological/biochemical/geometric priors encoded in the loss functions of AlphaFold2 were discarded in AlphaFold3.  

![img](https://miangoar.github.io/images/proteins/00050_af3_8.png)

...tomorrow will be another day ğŸ˜®â€ğŸ’¨  

![img](https://miangoar.github.io/images/proteins/00050_af3_9.png)
